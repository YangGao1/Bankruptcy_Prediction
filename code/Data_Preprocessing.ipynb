{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "random_state=42\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature to use\n",
    "'''\n",
    "close price \n",
    "assetturnover\n",
    "Total Assets\n",
    "ROA\n",
    "total_equity/total_liability\n",
    "Earnings per Share\n",
    "Net Operating Cash Flows\n",
    "EBIT Margin\n",
    "'''\n",
    "added_columns=['gdp','unemployment_rate','baa'] # This column contains economic data variables\n",
    "sample_columns=['prcc_f','at','oancf','revt','epsfi','ebit','lct','lt','seq','ni','ch','stalt','costat','fyear','spcseccd']+added_columns\n",
    "columns_selected=['prcc_f','at','epsfi','ebit_margin','total_equity/total_liability']+added_columns\n",
    "preditor=['stalt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.experimental import enable_iterative_imputer\\nfrom sklearn.impute import IterativeImputer\\nfrom sklearn.ensemble import RandomForestRegressor\\ndef handle_missing(df_healthy,df_bankruptcy):\\n    columns_to_delete_b=['pll','tie','unwcc','ustdnc','amgw','pvcl','udvp','txtubtxtr','wdp','teq','dt']\\n    columns_to_delete_h=['unwcc','ustdnc','pvcl','udvp','pll','tie','wdp','amgw','txtubtxtr','teq','dt']\\n    object_columns=['indfmt', 'consol', 'popsrc', 'datafmt', 'tic', 'curcd', 'costat','fic', 'incorp']\\n    df_healthy=df_healthy.drop(columns=columns_to_delete_h+object_columns)\\n    df_bankruptcy=df_bankruptcy.drop(columns=columns_to_delete_b+object_columns)\\n    imp=IterativeImputer(estimator=RandomForestRegressor(),n_nearest_features=5,verbose=1,random_state=random_state)\\n    df_all=df_bankruptcy.values\\n    df=imp.fit_transform(df_all)\\n    return df_all\\n    #random regressor imputation\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def handle_missing(df_healthy,df_bankruptcy):\n",
    "    columns_to_delete_b=['pll','tie','unwcc','ustdnc','amgw','pvcl','udvp','txtubtxtr','wdp','teq','dt']\n",
    "    columns_to_delete_h=['unwcc','ustdnc','pvcl','udvp','pll','tie','wdp','amgw','txtubtxtr','teq','dt']\n",
    "    object_columns=['indfmt', 'consol', 'popsrc', 'datafmt', 'tic', 'curcd', 'costat','fic', 'incorp']\n",
    "    df_healthy=df_healthy.drop(columns=columns_to_delete_h+object_columns)\n",
    "    df_bankruptcy=df_bankruptcy.drop(columns=columns_to_delete_b+object_columns)\n",
    "    imp=IterativeImputer(estimator=RandomForestRegressor(),n_nearest_features=5,verbose=1,random_state=random_state)\n",
    "    df_all=df_bankruptcy.values\n",
    "    df=imp.fit_transform(df_all)\n",
    "    return df_all\n",
    "    #random regressor imputation\n",
    "'''\n",
    "# This method is not good enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_economic():\n",
    "    # GDP columns\n",
    "    df_gdp=pd.read_csv('../data/economic_data/gdp.csv',parse_dates=[0],names=['year','gdp'],header=0)\n",
    "    df_gdp['gdp']=df_gdp['gdp'].pct_change()\n",
    "    df_gdp['year']=df_gdp['year'].apply(lambda x: x.year)\n",
    "    \n",
    "    #unemployment columns\n",
    "    df_un=pd.read_csv('../data/economic_data/unemployment_rate.csv',parse_dates=[0],names=['year1','unemployment_rate'],header=0)\n",
    "    df_un['unemployment_rate']=df_un['unemployment_rate']/100\n",
    "    df_un['year1']=df_un['year1'].apply(lambda x: x.year)\n",
    "    \n",
    "    #bbb spread\n",
    "    df_baa=pd.read_csv('../data/economic_data/baa_yield.csv',parse_dates=[0],names=['year2','baa'],header=0)\n",
    "    df_baa['baa']=df_baa['baa']/100\n",
    "    df_baa['year2']=df_baa['year2'].apply(lambda x:x.year)\n",
    "    df_baa=df_baa.groupby('year2').mean().reset_index(level=0) # 12 month baa yield average\n",
    "    \n",
    "    # merge two datasheet\n",
    "    df=df_gdp.merge(df_un,how='left',left_on='year',right_on='year1').drop(columns='year1')\n",
    "    df=df.merge(df_baa,how='left',left_on='year',right_on='year2').drop(columns='year2')\n",
    "    return df.dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(freq=0.01,columns=sample_columns):\n",
    "    #filename:healthy or bankruptcy\n",
    "    df1=pd.read_csv('../data/accouting_data/healthy_accouting_stalt.csv')\n",
    "    df2=pd.read_csv('../data/accouting_data/bankruptcy_accouting_stalt.csv')\n",
    "    df2['stalt']=1.0 #label bankruptcy\n",
    "    df1['stalt']=0.0 # label healthy\n",
    "    \n",
    "     # fill original sector in order to sample\n",
    "    df1['spcseccd'].fillna(0,inplace=True) \n",
    "    df2['spcseccd'].fillna(0,inplace=True)\n",
    "    \n",
    "    \n",
    "    #merge data\n",
    "    df=handle_economic()\n",
    "    df1=df1.merge(df,how='left',left_on='fyear',right_on='year').drop(columns='year')\n",
    "    df2=df2.merge(df,how='left',left_on='fyear',right_on='year').drop(columns='year')\n",
    "    \n",
    "    # naive ways of handling nan data(reasonable)\n",
    "    df1=df1[df1['costat']=='A'] #get all active companies data\n",
    "    df1=df1[columns].dropna()\n",
    "    df2=df2[columns].dropna()\n",
    "    \n",
    "    \n",
    "    sample_df=df1.groupby('spcseccd').apply(lambda x: x.sample(frac=freq,random_state=random_state))\n",
    "    # drop spcseccd columns in order to reset index\n",
    "    sample_df.drop(columns='spcseccd',inplace=True)\n",
    "    sample_df.reset_index(level=0,inplace=True)\n",
    "    #statified sample\n",
    "    #cols = sample_df.columns.tolist()\n",
    "    #cols=cols[-1:] + cols[:-1]\n",
    "    sample_df=sample_df[columns]\n",
    "    df_final=sample_df.append(df2).reset_index().drop(columns='index')\n",
    "    \n",
    "    # compute ratio\n",
    "    #1. ebit margin\n",
    "    df_final['ebit_margin']=df_final['ebit']/df_final['revt']\n",
    "    df_final.drop(columns='ebit',inplace=True)\n",
    "    \n",
    "    #2. ROA\n",
    "    #df_final['roa']=df_final['ni']/df_final['at']\n",
    "    #df_final.drop(columns='ni',inplace=True)\n",
    "    \n",
    "    #3.quick ratio\n",
    "    #df_final['quick_ratio']=df_final['ch']/df_final['lct']\n",
    "    #df_final.drop(columns=['ch','lct'],inplace=True)\n",
    "    \n",
    "    #4. asset turnover\n",
    "    #df_final['asset_turnover']=df_final['revt']/df_final['at']\n",
    "    #df_final.drop(columns='revt',inplace=True)\n",
    "    \n",
    "    # 5. cash flow return\n",
    "    #df_final['cash_flow_to_asset']=df_final['oancf']/df_final['at']\n",
    "    #df_final.drop(columns='oancf',inplace=True)\n",
    "    \n",
    "    #6. total equity/total liablity\n",
    "    df_final['total_equity/total_liability']=df_final['seq']/df_final['lt']\n",
    "    \n",
    "    #5. get log on asset\n",
    "    df_final['at']=np.log(df_final['at'])\n",
    "    df_final['prcc_f']=np.log(df_final['prcc_f'])\n",
    "    \n",
    "    #drop inf value\n",
    "    df_final=df_final.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    return df_final.dropna().copy()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_train(df,columns=columns_selected,pred=preditor,random_state=random_state):\n",
    "    #handle with nan data\n",
    "    X=df[columns_selected]\n",
    "    y=df[pred]\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=random_state,stratify=y)\n",
    "    \n",
    "    return X_train,X_test,y_train.values.flatten(),y_test.values.flatten()\n",
    "    \n",
    "    #select feature for ML training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(model,X_test,y_test,threshold=0.5,type_=None):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Model: - trained model such as Logistic Regression\n",
    "    X_test - np.array of test set\n",
    "    y_test -binary label in range {0,1} \n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        return 0.0,0.0,0.0\n",
    "    predicted_prob=np.zeros(X_test.shape[0])\n",
    "    predicted_binary=np.zeros(X_test.shape[0])\n",
    "    if type_==1:\n",
    "        #Logistic Regression using sklearn\n",
    "        predicted_prob=model.predict_proba(X_test)[:,1]\n",
    "        predicted_binary=(predicted_prob>threshold).astype(int)\n",
    "    \n",
    "    if type_==0:\n",
    "        predicted_prob=model.predict(X_test)\n",
    "        predicted_binary=(predicted_prob>threshold).astype(int)\n",
    "    \n",
    "    fpr,tpr,_=metrics.roc_curve(y_test,predicted_prob,pos_label=1)\n",
    "    \n",
    "    #compute AUC from prediction score\n",
    "    roc_auc=metrics.auc(fpr,tpr)\n",
    "    ks=np.max(tpr-fpr)\n",
    "    \n",
    "    #accuracy score\n",
    "    accuracy_score=metrics.accuracy_score(y_test,predicted_binary)\n",
    "        \n",
    "    try:\n",
    "        plt.title('Logistic Regression ROC Curve')\n",
    "        plt.plot(fpr,tpr,'b',label='AUC=%0.2f' % roc_auc)\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.plot([0,1],[0,1],'r--')\n",
    "        plt.xlabel('False Positive rate')\n",
    "        plt.ylabel('True Positive rate')\n",
    "        plt.savefig('../picture/ROC_curve_1.png')\n",
    "        plt.show()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return roc_auc,accuracy_score,ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
